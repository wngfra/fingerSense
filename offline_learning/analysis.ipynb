{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4775914",
   "metadata": {},
   "source": [
    "# Prepare custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 wngfra.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from bidict import bidict\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class Texture:\n",
    "    \"\"\" Create a bidict from a texture name list.\"\"\"\n",
    "\n",
    "    def __init__(self, texture_names):\n",
    "        self.texture_by_id = bidict()\n",
    "        for i, tn in enumerate(set(texture_names)):\n",
    "            self.texture_by_id[tn] = i\n",
    "\n",
    "    def get_id(self, texture_name: str):\n",
    "        return self.texture_by_id[texture_name]\n",
    "\n",
    "    def get_name(self, texture_id: int):\n",
    "        return self.texture_by_id.inverse[texture_id]\n",
    "\n",
    "\n",
    "class TacDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.filelist = [y for x in os.walk(\n",
    "            root_dir) for y in glob.glob(os.path.join(x[0], '*.npy'))]\n",
    "        self.params = [(0.0, 0.0)] * len(self.filelist)\n",
    "        self.texture_names = []\n",
    "        for i, filename in enumerate(self.filelist):\n",
    "            basename = os.path.basename(filename)\n",
    "            namegroups = basename.split('_')\n",
    "\n",
    "            self.texture_names.append(namegroups[0])\n",
    "            self.params[i] = [float(re.search(r\"\\d+.\\d+\", namegroups[1]).group(0)),\n",
    "                              float(re.search(r\"\\d+.\\d+\", namegroups[2]).group(0))]\n",
    "        self.textures = Texture(self.texture_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = os.path.join(self.root_dir, self.filelist[index])\n",
    "        rawdata  = np.load(filename)\n",
    "        tacdata  = rawdata[:, :16]\n",
    "        wrench   = rawdata[:, -6:]\n",
    "        texture_name = self.texture_names[index]\n",
    "        if self.transform:\n",
    "            tacdata = self.transform(tacdata)\n",
    "        return np.hstack([tacdata, wrench]), self.params[index], self.textures.get_id(texture_name) \n",
    "\n",
    "    def get_texture_name(self, texture_id):\n",
    "        return self.textures.get_name(texture_id)\n",
    "\n",
    "    \n",
    "\"\"\" Custom transforms \"\"\"\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, axis=0):\n",
    "        self.axis = axis\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return (sample - np.mean(sample, axis=self.axis)) / np.std(sample, axis=self.axis)\n",
    "\n",
    "\n",
    "class ToFourierBasis(object):\n",
    "    \"\"\" Transform a sample to its Fourier basis coefficients \"\"\"\n",
    "    def __init__(self, n_basis, period) -> None:\n",
    "        self.basis = basis.Fourier(\n",
    "            [0, 2 * np.pi], n_basis=n_basis, period=period)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # Input sample matrix\n",
    "        # Each row contains one observation and each column represents one variable\n",
    "        fd = FDataGrid(sample.T).to_basis(self.basis)\n",
    "        coeffs = fd.coefficients.squeeze()\n",
    "\n",
    "        return coeffs.T\n",
    "\n",
    "transform = transforms.Compose([Normalize(axis=0)])\n",
    "ds = TacDataset('../data', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b4c24",
   "metadata": {},
   "source": [
    "# Group all samples and labels, save to `.mat` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ab4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "mdata = []\n",
    "mlabels = []\n",
    "\n",
    "for i, (sample, param, label) in enumerate(ds):\n",
    "    mdata.append(sample[:, :16])\n",
    "    mlabels.append(label)\n",
    "    \n",
    "mdata = np.asarray(mdata, dtype=object)\n",
    "\n",
    "tacmat = {\"mdata\": mdata, \"labels\": mlabels}\n",
    "savemat(\"TacMat\", tacmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefdc57b",
   "metadata": {},
   "source": [
    "# Visualize raw data in time and frequency domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f0cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import fft\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "def plot2(item):\n",
    "    data, param, label = item[0], item[1], item[2]\n",
    "    data = data[:, :16]\n",
    "    L = data.shape[0]\n",
    "    Y = np.fft.fft(data, axis=0)\n",
    "    Ys = np.abs(Y / L)\n",
    "    Ys = Ys[1:L//2+1, :]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.plot(data)\n",
    "    plt.subplot(212)\n",
    "    plt.plot(Ys[:64, :])\n",
    "    title = ds.get_texture_name(label)\n",
    "    plt.suptitle(\"{} @ {}N and {}mmps\".format(title, param[0], param[1]))\n",
    "    plt.show()\n",
    "\n",
    "for item in ds:\n",
    "    plot2(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3e460",
   "metadata": {},
   "source": [
    "# Compress data with Tucker decomposition\n",
    "1. Compute covariance matrix for each multi-channel frequency series\n",
    "2. Stack covariance matrix into a 3D covariance tensor $T \\in \\mathbb{R}^{C \\times C \\times N}$\n",
    "3. Use core tensor $\\mathcal{G}$ of the Tucker decomposition $T = \\mathcal{G} \\times_1 U_1 \\times_2 U_2 \\times_3 U_3$ as a compressed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb854774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.fft import fft\n",
    "from skfda import FDataGrid\n",
    "from skfda.representation import basis\n",
    "from tensorly.decomposition import non_negative_tucker\n",
    "\n",
    "N_BASIS = 33\n",
    "STRIDE = 128\n",
    "WINDOW_SIZE = 256\n",
    "\n",
    "fd_basis = basis.Fourier([0, 2 * np.pi], n_basis=N_BASIS, period=1)\n",
    "\n",
    "def compute_cov_fda(data):\n",
    "    ''' Compute covariance matrix with functional basis decomposition.'''\n",
    "    fd = FDataGrid(data.T).to_basis(fd_basis)\n",
    "    coeffs = fd.coefficients.squeeze()\n",
    "    return np.cov(coeffs.T)\n",
    "\n",
    "def compute_cov_fft(data):\n",
    "    L = data.shape[0]\n",
    "    Y = fft(data, axis=0)\n",
    "    Ys = np.abs(Y / L)\n",
    "    return np.cov(Ys[1:L//2+1, :])\n",
    "\n",
    "cov_array = []\n",
    "labels = []\n",
    "\n",
    "for i, (sample, param, label) in enumerate(ds):\n",
    "    cov = compute_cov_fda(sample)\n",
    "    cov_array.append(cov)\n",
    "    labels.append(ds.get_texture_name(label))\n",
    "\n",
    "cov_tensor = np.transpose(np.asarray(cov_array), [1, 2, 0])\n",
    "core, factors = non_negative_tucker(cov_tensor, rank=(3, 1, cov_tensor.shape[2]))\n",
    "core3d = core.squeeze().T  # get projected vectors\n",
    "\n",
    "df0 = pd.DataFrame(labels, columns=[\"texture\"])\n",
    "df1 = pd.DataFrame(core3d, columns=[\"x1\", \"x2\", \"x3\"])\n",
    "df  = pd.concat([df0, df1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add7139",
   "metadata": {},
   "source": [
    "# Visualize compressed core tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ccb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "shift = None\n",
    "df_ = df.iloc[3:, :]\n",
    "\n",
    "textures = df_[\"texture\"].unique()\n",
    "cmap = plt.cm.get_cmap(\"plasma\", len(textures))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "for i, texture in enumerate(textures):\n",
    "    X = df_.loc[df_[\"texture\"] == texture]\n",
    "    # plot core vectors\n",
    "    xs, ys, zs = X[\"x1\"], X[\"x2\"], X[\"x3\"]\n",
    "    if shift is not None:\n",
    "        xs, ys, zs = shift(xs), shift(ys), shift(zs)\n",
    "    ax.scatter(xs, ys, zs, s=20, c=np.tile(cmap(i), (len(xs), 1)))\n",
    "ax.legend(textures)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d711f36",
   "metadata": {},
   "source": [
    "# Construct RNN-AutoEncoder (RAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" Recurent Variational Autoencoder \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, device, dropout=0.3):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "        \n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, output_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        packed_in = pack_padded_sequence(x[0].to(self.device), x[1].cpu().numpy(), batch_first=True)\n",
    "        rnn_out, self.hidden = self.rnn(packed_in)\n",
    "        x_in = self.hidden[-1].squeeze()\n",
    "        mu = self.fc_mu(x_in)\n",
    "        var = self.fc_var(x_in)\n",
    "        \n",
    "        return mu\n",
    "    \n",
    "    def init_hidden(self, batch_dim):\n",
    "        return (torch.zeros(self.n_layers, batch_dim, self.hidden_dim, device=self.device),\n",
    "                torch.zeros(self.n_layers, batch_dim, self.hidden_dim, device=self.device))\n",
    "\n",
    "\n",
    "class RVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, encoding_dim, extra_dim, output_dim, n_layers, device):\n",
    "        super(RVAE, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.encoder = Encoder(input_dim, hidden_dim, encoding_dim, n_layers, device)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(encoding_dim + extra_dim, 4 * (encoding_dim + extra_dim)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * (encoding_dim + extra_dim), output_dim),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x[:2])\n",
    "        x_in = torch.hstack([encoded, x[2].to(self.device)])\n",
    "        y = self.classifier(x_in)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "\"\"\" Custom collate functions\"\"\"\n",
    "\n",
    "class PadSequence(object):\n",
    "    def __call__(self, batch):\n",
    "        # Each element in \"batch\" is a tuple (data, label).\n",
    "        # Sort the batch in the descending order\n",
    "        sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "        # Get each sequence and pad it\n",
    "        sequences = [torch.tensor(x[0], dtype=torch.float) for x in sorted_batch]\n",
    "        sequences_padded = pad_sequence(\n",
    "            sequences, batch_first=True)\n",
    "        # Store the length of each sequence\n",
    "        lengths = torch.tensor([len(x) for x in sequences])\n",
    "        params = torch.tensor(list(map(lambda x: x[1], sorted_batch)), dtype=torch.float)\n",
    "        labels = torch.tensor(list(map(lambda x: x[2], sorted_batch)))\n",
    "        return sequences_padded, lengths, params, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a98b95",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "INPUT_DIM = 22\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "train_loader = DataLoader(ds, batch_size=BATCH_SIZE, collate_fn=PadSequence(), num_workers=6, shuffle=True)\n",
    "rvae = RVAE(input_dim=INPUT_DIM, hidden_dim=32, encoding_dim=3, extra_dim=2, output_dim=4, n_layers=2, device=device)\n",
    "\n",
    "def train_once(x, y, model, optimizer, criterion):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    target = y.to(device)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "    \n",
    "def train_model(data_loader, model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, (batch, lengths, params, targets) in enumerate(data_loader):\n",
    "            loss = train_once((batch, lengths, params), targets, model, optimizer, criterion)\n",
    "            running_loss += loss\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            if i % 10 == 9:    # print every 2000 mini-batches\n",
    "                print('Epoch {}, {:.2f}% - loss: {:.6f}'.format(epoch + 1, 100.0 * (i + 1.0) / len(data_loader), running_loss / 10))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    print(\"Training finished.\")\n",
    "    plt.plot(loss_list)\n",
    "    plt.show()\n",
    "    \n",
    "train_model(train_loader, rvae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
